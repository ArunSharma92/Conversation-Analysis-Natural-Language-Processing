Description: This project was done for my Social Computing Class ICSI 660. Here the dataset provided was a conversation between team members. The dataset has two seperate conversations from two different instances.

Firstly we had to run the two conversations from the dataset through the Stanford suite of tools and produce output for:
a) tokenizing
b) sentence splitting
c) part-of-speech tagging
d) lemmatizing
e) named entity recognition

The output file produced by the software was in XML format as shown below:

<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="CoreNLP-to-HTML.xsl" type="text/xsl"?> <root>
<document> <sentences>
<sentence id="1"> <tokens>
<token id="1">
<word>shelly</word>
<lemma>shelly</lemma> <CharacterOffsetBegin>0</CharacterOffsetBegin> <CharacterOffsetEnd>6</CharacterOffsetEnd> <POS>NN</POS>
<NER>O</NER> </token>
<token id="2">
<word>-LRB-</word>
        
<lemma>-lrb-</lemma> <CharacterOffsetBegin>7</CharacterOffsetBegin> <CharacterOffsetEnd>8</CharacterOffsetEnd> <POS>-LRB-</POS>
<NER>O</NER>
</token> ...
... </sentence>
</sentences> </document>
</root>

Secondly we had to write code to read the output xml files obtained after processing from the Stanford Core NLP tool 
and count the number of pronouns for each participant in the conversation.
I wrote the code in C++ based on the format of the files as mentioned above.

The output files that have identified each pronoun in the conversation. The pronouns are identified by the following xml tags:
<POS>PRP</POS>
and
<POS>PRP$</POS>
The results obtained were then used to prove and disprove Hypotheses that were given to us based on our dataset.
